---
title: "Classifier Naïve Bayes"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(tidytext)
library(tidymodels)
library(e1071)
library(janitor)
library(Matrix)
```
# Cargar bases de datos
```{r}
data = read_delim("prueba_all_stories.csv")
```

```{r}
head(data)
summary(data)
```

```{r}
matrix = read_delim("matrix_paranormal.csv")
```

```{r}
head(matrix)
summary(matrix)
```

# Limpieza de datos

```{r}
data <- data %>%
  clean_names() %>%
  filter(!is.na(text), !is.na(category)) %>%
  mutate(
    text = str_to_lower(text),
    text = str_replace_all(text, "[^a-zA-Z\\s]", ""),
    text = str_squish(text),
    story_id = row_number()           # IDs unicos
  )
```

# Verificación de categorías

```{r}
print(paste("Número total de relatos:", nrow(data)))
print("Distribución por categoría:")
print(table(data$category))
```
# Cargar la sparse matrix

```{r}
model_data <- matrix
```

# Clasificador Naïve Bayes con library(e071)

## División en training y test sets

```{r}
set.seed(1234)
paranormal_split <- initial_split(model_data, prop = 0.7)
```

```{r}
paranormal_train <- training(paranormal_split)
paranormal_test <- testing(paranormal_split)
```

## Entrenar el clasificador

```{r}
NB_pn <- naiveBayes(category ~ ., data = paranormal_train)
```

```{r}
y_pred <- predict(NB_pn, newdata = paranormal_test)
y_true <- paranormal_test$category
```

```{r}
all_levels <- union(levels(as.factor(y_true)), levels(as.factor(y_pred)))
y_pred <- factor(y_pred, levels = all_levels)
y_true <- factor(y_true, levels = all_levels)
```

## Evaluación del modelo

```{r}
cm <- table(Actual = y_true, Predicted = y_pred)
print("Matriz de Confusión (e1071):")
print(cm)
```

```{r}
accuracy <- sum(diag(cm)) / sum(cm)
print(paste("Accuracy (e1071):", round(accuracy, 4)))
```

```{r}
calculate_metrics <- function(cm, class_name) {
  if (!class_name %in% rownames(cm)) {
    return(list(precision = NA, recall = NA, f1 = NA))    # Verificar si clase existe dentro de cm
  }
  
  class_idx <- which(rownames(cm) == class_name)  # Posicion de la clase
  tp <- cm[class_idx, class_idx]         # True Positives
  fp <- sum(cm[, class_idx]) - tp        # False positives
  fn <- sum(cm[class_idx, ]) - tp        # False negatives
  
  precision <- ifelse(tp + fp == 0, 0, tp / (tp + fp))
  recall <- ifelse(tp + fn == 0, 0, tp / (tp + fn))
  f1 <- ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
  
  return(list(
    precision = precision,
    recall = recall,
    f1 = f1
  ))
}
```

```{r}
classes <- rownames(cm)
metrics_list <- list()

cat("Métricas por clase:\n")
for (class in classes) {
  metrics <- calculate_metrics(cm, class)
  metrics_list[[class]] <- metrics
  
  cat(paste("Clase:", class, "\n"))
  cat(paste("  Precision:", round(metrics$precision, 4), "\n"))
  cat(paste("  Recall:", round(metrics$recall, 4), "\n"))
  cat(paste("  F1-Score:", round(metrics$f1, 4), "\n\n"))
}
```
## Métricas promedio (macro average)
```{r}
macro_precision_e1071 <- mean(sapply(metrics_list, function(x) x$precision), na.rm = TRUE)
macro_recall_e1071 <- mean(sapply(metrics_list, function(x) x$recall), na.rm = TRUE)
macro_f1_e1071 <- mean(sapply(metrics_list, function(x) x$f1), na.rm = TRUE)

cat("Promedios (e1071):\n")
cat(paste("  Macro Precision:", round(macro_precision_e1071, 4), "\n"))
cat(paste("  Macro Recall:", round(macro_recall_e1071, 4), "\n"))
cat(paste("  Macro F1-Score:", round(macro_f1_e1071, 4), "\n\n"))
```
# Clasificador Naïve Bayes con library(naivebayes)

```{r}
library(naivebayes)
```

## División en training y test sets con naivebayes
```{r}
NB_naivebayes <- naive_bayes(category ~ ., data = paranormal_train)
```

## Entrenar el clasificador naivebayes

```{r}
y_pred_nb <- predict(NB_naivebayes, newdata = paranormal_test)
y_pred_nb <- factor(y_pred_nb, levels = all_levels)
```

## Evaluación con naivebayes

```{r}
cm_nb <- table(Actual = y_true, Predicted = y_pred_nb)
print("Matriz de Confusión (naivebayes):")
print(cm_nb)
```

```{r}
accuracy_nb <- sum(diag(cm_nb)) / sum(cm_nb)
print(paste("Accuracy (naivebayes):", round(accuracy_nb, 4)))
```

```{r}
classes_nb <- rownames(cm_nb)
metrics_list_nb <- list()
cat("Métricas por clase (naivebayes):\n")
for (class in classes_nb) {
  metrics <- calculate_metrics(cm_nb, class)
  metrics_list_nb[[class]] <- metrics
  
  cat(paste("Clase:", class, "\n"))
  cat(paste("  Precision:", round(metrics$precision, 4), "\n"))
  cat(paste("  Recall:", round(metrics$recall, 4), "\n"))
  cat(paste("  F1-Score:", round(metrics$f1, 4), "\n\n"))
}
```

## Promedios naivebayes
```{r}
macro_precision_nb <- mean(sapply(metrics_list_nb, function(x) x$precision), na.rm = TRUE)
macro_recall_nb <- mean(sapply(metrics_list_nb, function(x) x$recall), na.rm = TRUE)
macro_f1_nb <- mean(sapply(metrics_list_nb, function(x) x$f1), na.rm = TRUE)

cat("Promedios (naivebayes):\n")
cat(paste("  Macro Precision:", round(macro_precision_nb, 4), "\n"))
cat(paste("  Macro Recall:", round(macro_recall_nb, 4), "\n"))
cat(paste("  Macro F1-Score:", round(macro_f1_nb, 4), "\n\n"))
```

# Comparación entre clasificadores e1071 y naivebayes

```{r}
cat(paste("Accuracy e1071:", round(accuracy, 4), "\n"))
cat(paste("Accuracy naivebayes:", round(accuracy_nb, 4), "\n"))
cat(paste("Diferencia:", round(accuracy_nb - accuracy, 4), "\n\n"))

cat(paste("Macro F1 e1071:", round(macro_f1_e1071, 4), "\n"))
cat(paste("Macro F1 naivebayes:", round(macro_f1_nb, 4), "\n"))
cat(paste("Diferencia:", round(macro_f1_nb - macro_f1_e1071, 4), "\n\n"))
```

## Con distribución Poisson

```{r}
library(naivebayes)
```

```{r}
NB_naivebayes_poisson <- naive_bayes(category ~ ., data = paranormal_train, usepoisson = TRUE)
```

```{r}
y_pred_nb_poisson <- predict(NB_naivebayes_poisson, newdata = paranormal_test)
y_pred_nb_poisson <- factor(y_pred_nb_poisson, levels = all_levels)
```

```{r}
cm_nb_poisson <- table(Actual = y_true, Predicted = y_pred_nb_poisson)
print("Matriz de Confusión (naivebayes Poisson):")
print(cm_nb_poisson)
```

```{r}
accuracy_nb_poisson <- sum(diag(cm_nb_poisson)) / sum(cm_nb_poisson)
print(paste("Accuracy (naivebayes Poisson):", round(accuracy_nb_poisson, 4)))
```

```{r}
metrics_list_nb_poisson <- list()
```


```{r}
cat("Métricas por clase (naivebayes Poisson):\n")
for (class in rownames(cm_nb_poisson)) {
  metrics <- calculate_metrics(cm_nb_poisson, class)
  metrics_list_nb_poisson[[class]] <- metrics
  cat(paste("Clase:", class, "\n"))
  cat(paste("  Precision:", round(metrics$precision, 4), "\n"))
  cat(paste("  Recall:", round(metrics$recall, 4), "\n"))
  cat(paste("  F1-Score:", round(metrics$f1, 4), "\n\n"))
}
```

```{r}
macro_precision_nb_poisson <- mean(sapply(metrics_list_nb_poisson, function(x) x$precision), na.rm = TRUE)
macro_recall_nb_poisson <- mean(sapply(metrics_list_nb_poisson, function(x) x$recall), na.rm = TRUE)
macro_f1_nb_poisson <- mean(sapply(metrics_list_nb_poisson, function(x) x$f1), na.rm = TRUE)
cat("Promedios (naivebayes Poisson):\n")
cat(paste("  Macro Precision:", round(macro_precision_nb_poisson, 4), "\n"))
cat(paste("  Macro Recall:", round(macro_recall_nb_poisson, 4), "\n"))
cat(paste("  Macro F1-Score:", round(macro_f1_nb_poisson, 4), "\n\n"))
```

# Laplace 

```{r}
# Instalar caret si no está instalado
if (!require(caret)) install.packages("caret")
library(caret)
library(e1071)
library(dplyr)
```


```{r}
set.seed(1234)

train_control <- trainControl(method = "cv", number = 3)

```


```{r}
# Grid para probar varios valores del parámetro laplace (suavizado)
laplace_grid <- expand.grid(
  laplace = seq(0, 2, by = 0.25),
  usekernel = FALSE,
  adjust = 1
)

```

```{r}
# Entrenar el modelo Naïve Bayes buscando el mejor laplace
nb_laplace_tuned <- train(
  category ~ ., 
  data = paranormal_train,
  method = "naive_bayes",
  trControl = train_control,
  tuneGrid = laplace_grid,
  metric = "Accuracy"
)
```


```{r}
print(nb_laplace_tuned)
cat("Mejor Laplace:", nb_laplace_tuned$bestTune$laplace, "\n")
```

```{r}
# Predecir en conjunto de prueba
y_pred_laplace <- predict(nb_laplace_tuned, newdata = paranormal_test)
y_true <- paranormal_test$category
```

```{r}
# Asegurar que se toman todos los niveles para evitar warnings
all_levels <- union(levels(as.factor(y_true)), levels(as.factor(y_pred_laplace)))
y_pred_laplace <- factor(y_pred_laplace, levels = all_levels)
y_true <- factor(y_true, levels = all_levels)
```

```{r}
# Matriz de confusión
cm_laplace <- table(Actual = y_true, Predicted = y_pred_laplace)
print("Matriz de Confusión (Laplace smoothing):")
print(cm_laplace)
```

```{r}
# Calcular accuracy
accuracy_laplace <- sum(diag(cm_laplace)) / sum(cm_laplace)
print(paste("Accuracy (Laplace smoothing):", round(accuracy_laplace, 4)))

```

```{r}
# Función para calcular precisión, recall y F1 por clase
calculate_metrics <- function(cm, class_name) {
  if (!class_name %in% rownames(cm)) {
    return(list(precision = NA, recall = NA, f1 = NA))
  }
  class_idx <- which(rownames(cm) == class_name)
  tp <- cm[class_idx, class_idx]
  fp <- sum(cm[, class_idx]) - tp
  fn <- sum(cm[class_idx, ]) - tp
  precision <- ifelse(tp + fp == 0, 0, tp / (tp + fp))
  recall <- ifelse(tp + fn == 0, 0, tp / (tp + fn))
  f1 <- ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
  return(list(precision = precision, recall = recall, f1 = f1))
}

```

```{r}
# Calcular métricas por clase
classes <- rownames(cm_laplace)
metrics_list_laplace <- list()
cat("Métricas por clase (Laplace smoothing):\n")
for (class in classes) {
  metrics <- calculate_metrics(cm_laplace, class)
  metrics_list_laplace[[class]] <- metrics
  cat(paste("Clase:", class, "\n"))
  cat(paste("  Precision:", round(metrics$precision, 4), "\n"))
  cat(paste("  Recall:", round(metrics$recall, 4), "\n"))
  cat(paste("  F1-Score:", round(metrics$f1, 4), "\n\n"))
}
```

```{r}
# Calcular promedios macro (promedio simple de todas las clases)
macro_precision_laplace <- mean(sapply(metrics_list_laplace, function(x) x$precision), na.rm = TRUE)
macro_recall_laplace <- mean(sapply(metrics_list_laplace, function(x) x$recall), na.rm = TRUE)
macro_f1_laplace <- mean(sapply(metrics_list_laplace, function(x) x$f1), na.rm = TRUE)

```

```{r}
cat("Promedios (Laplace smoothing):\n")
cat(paste("  Macro Precision:", round(macro_precision_laplace, 4), "\n"))
cat(paste("  Macro Recall:", round(macro_recall_laplace, 4), "\n"))
cat(paste("  Macro F1-Score:", round(macro_f1_laplace, 4), "\n\n"))
```